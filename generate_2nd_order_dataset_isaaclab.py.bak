# Copyright (c) 2024-2025, The Isaac Lab Project Developers.
# All rights reserved.
#
# SPDX-License-Identifier: Apache-2.0

"""Generate 2nd-order (q, q_dot) demonstration dataset using cuRobo motion planner.

This script generates expert trajectories containing both joint positions and velocities
for training 2nd-order Flow Matching models with Geometric Fabrics guidance.

The output dataset includes:
- obs/joint_pos: Joint positions (T, 7)
- obs/joint_vel: Joint velocities (T, 7)
- obs/eef_pos: End-effector position (T, 3)
- obs/eef_quat: End-effector quaternion (T, 4)
- obs/obstacle_pos: Obstacle positions for context (T, K*3)
- actions: Velocity field [q_dot, q_ddot] (T, 14)

Example:
    python generate_2nd_order_dataset.py \\
        --task Isaac-Reach-Franka-v0 \\
        --num_demos 100 \\
        --dataset_file ./datasets/franka_2nd_order.hdf5 \\
        --num_envs 4 \\
        --device cuda:0
"""

"""Launch Isaac Sim Simulator first."""

import argparse
import contextlib
import os
import h5py
import numpy as np
import torch

from isaaclab.app import AppLauncher

# Add argparse arguments
parser = argparse.ArgumentParser(description="Generate 2nd-order cuRobo demonstrations.")
parser.add_argument("--task", type=str, default="Isaac-Reach-Franka-v0", help="Name of the task.")
parser.add_argument("--num_demos", type=int, default=100, help="Number of successful demonstrations.")
parser.add_argument(
    "--dataset_file",
    type=str,
    default="./datasets/franka_2nd_order.hdf5",
    help="File path to export recorded demos.",
)
parser.add_argument("--num_envs", type=int, default=1, help="Number of parallel environments.")
parser.add_argument(
    "--num_success_steps",
    type=int,
    default=10,
    help="Consecutive success steps to conclude demo.",
)
parser.add_argument("--dt", type=float, default=0.01, help="Control timestep for trajectory.")
# Append AppLauncher cli args
AppLauncher.add_app_launcher_args(parser)
args_cli = parser.parse_args()

# Launch the simulator
app_launcher = AppLauncher(args_cli)
simulation_app = app_launcher.app

"""Rest everything follows."""

import gymnasium as gym
import omni.log

from isaaclab.envs import ManagerBasedRLEnvCfg
import isaaclab_tasks  # noqa: F401
from isaaclab_tasks.utils.parse_cfg import parse_env_cfg


class SecondOrderDemoCollector:
    """Collects 2nd-order demonstration data from cuRobo trajectories."""

    def __init__(self, num_envs: int, device: str, dt: float = 0.01):
        self.num_envs = num_envs
        self.device = device
        self.dt = dt

        # Storage for current episode per environment
        self.episode_data = {i: self._create_empty_episode() for i in range(num_envs)}

    def _create_empty_episode(self) -> dict:
        """Create empty episode storage."""
        return {
            "joint_pos": [],
            "joint_vel": [],
            "eef_pos": [],
            "eef_quat": [],
            "obstacle_pos": [],
            "actions": [],  # [q_dot, q_ddot]
        }

    def add_step(
        self,
        env_id: int,
        joint_pos: torch.Tensor,
        joint_vel: torch.Tensor,
        eef_pos: torch.Tensor,
        eef_quat: torch.Tensor,
        obstacle_pos: torch.Tensor,
    ):
        """Add a timestep to the episode.

        Args:
            env_id: Environment index
            joint_pos: Joint positions (7,)
            joint_vel: Joint velocities (7,)
            eef_pos: End-effector position (3,)
            eef_quat: End-effector quaternion (4,)
            obstacle_pos: Obstacle positions flattened (K*3,)
        """
        ep = self.episode_data[env_id]
        ep["joint_pos"].append(joint_pos.cpu().numpy())
        ep["joint_vel"].append(joint_vel.cpu().numpy())
        ep["eef_pos"].append(eef_pos.cpu().numpy())
        ep["eef_quat"].append(eef_quat.cpu().numpy())
        ep["obstacle_pos"].append(obstacle_pos.cpu().numpy())

    def finalize_episode(self, env_id: int) -> dict | None:
        """Finalize episode and compute actions (velocity field).

        Computes:
            - q_dot: joint velocities (from data)
            - q_ddot: joint accelerations (numerical derivative of q_dot)

        Returns:
            Finalized episode dict or None if too short
        """
        ep = self.episode_data[env_id]

        if len(ep["joint_pos"]) < 3:
            # Episode too short
            self.reset_episode(env_id)
            return None

        # Stack arrays
        joint_pos = np.stack(ep["joint_pos"], axis=0)  # (T, 7)
        joint_vel = np.stack(ep["joint_vel"], axis=0)  # (T, 7)
        eef_pos = np.stack(ep["eef_pos"], axis=0)  # (T, 3)
        eef_quat = np.stack(ep["eef_quat"], axis=0)  # (T, 4)
        obstacle_pos = np.stack(ep["obstacle_pos"], axis=0)  # (T, K*3)

        # Compute q_ddot from q_dot using finite differences
        # Central difference: (q_dot[t+1] - q_dot[t-1]) / (2*dt)
        q_ddot = np.zeros_like(joint_vel)
        q_ddot[1:-1] = (joint_vel[2:] - joint_vel[:-2]) / (2 * self.dt)
        q_ddot[0] = (joint_vel[1] - joint_vel[0]) / self.dt  # Forward difference
        q_ddot[-1] = (joint_vel[-1] - joint_vel[-2]) / self.dt  # Backward difference

        # Actions: [q_dot, q_ddot] as velocity field
        actions = np.concatenate([joint_vel, q_ddot], axis=-1)  # (T, 14)

        result = {
            "obs": {
                "joint_pos": joint_pos.astype(np.float32),
                "joint_vel": joint_vel.astype(np.float32),
                "eef_pos": eef_pos.astype(np.float32),
                "eef_quat": eef_quat.astype(np.float32),
                "obstacle_pos": obstacle_pos.astype(np.float32),
            },
            "actions": actions.astype(np.float32),
        }

        self.reset_episode(env_id)
        return result

    def reset_episode(self, env_id: int):
        """Reset episode storage for an environment."""
        self.episode_data[env_id] = self._create_empty_episode()


def save_demos_to_hdf5(demos: list[dict], output_path: str):
    """Save collected demonstrations to HDF5 file.

    Args:
        demos: List of episode dicts with obs and actions
        output_path: Path to save HDF5 file
    """
    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    with h5py.File(output_path, "w") as f:
        # Create data group
        data_grp = f.create_group("data")

        # Store metadata
        f.attrs["num_demos"] = len(demos)
        f.attrs["format"] = "gf_fm_2nd_order"

        for i, demo in enumerate(demos):
            demo_grp = data_grp.create_group(f"demo_{i}")

            # Store observations
            obs_grp = demo_grp.create_group("obs")
            for key, value in demo["obs"].items():
                obs_grp.create_dataset(key, data=value, compression="gzip")

            # Store actions
            demo_grp.create_dataset("actions", data=demo["actions"], compression="gzip")

            # Store episode length
            demo_grp.attrs["num_samples"] = len(demo["actions"])

    print(f"Saved {len(demos)} demonstrations to {output_path}")


def create_environment() -> tuple:
    """Create and configure the environment.

    Returns:
        tuple: (env, env_cfg, success_term)
    """
    try:
        env_cfg = parse_env_cfg(args_cli.task, device=args_cli.device, num_envs=args_cli.num_envs)
        env_cfg.env_name = args_cli.task.split(":")[-1]
    except Exception as e:
        omni.log.error(f"Failed to parse environment configuration: {e}")
        exit(1)

    # Extract success checking function
    success_term = None
    if hasattr(env_cfg.terminations, "success"):
        success_term = env_cfg.terminations.success
        env_cfg.terminations.success = None

    # Modify configuration for data generation
    is_datagen_task = "datagen" in args_cli.task.lower()

    if not is_datagen_task:
        env_cfg.terminations.time_out = None
        env_cfg.observations.policy.concatenate_terms = False
        env_cfg.commands.ee_pose.resampling_time_range = (10000.0, 10000.0)

    env = gym.make(args_cli.task, cfg=env_cfg).unwrapped
    return env, env_cfg, success_term


def initialize_curobo_planners(env) -> dict:
    """Initialize cuRobo motion planners for each environment."""
    from isaaclab_mimic.motion_planners.curobo.curobo_planner import CuroboPlanner
    from isaaclab_mimic.motion_planners.curobo.curobo_planner_cfg import CuroboPlannerCfg

    planners = {}
    for env_id in range(args_cli.num_envs):
        print(f"Initializing cuRobo planner for environment {env_id}...")
        planner_config = CuroboPlannerCfg.from_task_name(args_cli.task)

        if env_id != 0:
            planner_config.visualize_spheres = False
            planner_config.visualize_plan = False

        planners[env_id] = CuroboPlanner(
            env=env,
            robot=env.scene["robot"],
            config=planner_config,
            env_id=env_id,
        )

    return planners


def get_obstacle_positions(env, env_id: int) -> torch.Tensor:
    """Get obstacle positions from environment.

    Returns flattened obstacle positions. If no obstacles found,
    returns zeros.
    """
    # Try to get obstacle positions from scene
    obstacle_pos = []

    # Check for common obstacle naming patterns
    for name in env.scene.keys():
        if "obstacle" in name.lower() or "object" in name.lower():
            try:
                obj = env.scene[name]
                if hasattr(obj, "data") and hasattr(obj.data, "root_pos_w"):
                    pos = obj.data.root_pos_w[env_id, :3]  # (3,)
                    obstacle_pos.append(pos)
            except Exception:
                pass

    if len(obstacle_pos) == 0:
        # No obstacles - return target position as context
        command = env.command_manager.get_command("ee_pose")
        target_pos = command[env_id, :3]
        return target_pos

    # Stack and flatten
    return torch.cat(obstacle_pos, dim=-1)


def check_success(env, success_term, success_counters: torch.Tensor) -> tuple:
    """Check success condition for each environment."""
    if success_term is None:
        # Fallback: use subtask_terms for reach tasks
        if hasattr(env, 'observation_manager') and 'subtask_terms' in env.observation_manager._group_obs_term_cfgs:
            from isaaclab_tasks.manager_based.manipulation.reach.mdp.datagen_observations import reach_subtask_term_signal
            from isaaclab.managers import SceneEntityCfg

            ee_body_name = env.command_manager.get_term("ee_pose").cfg.body_name
            body_cfg = SceneEntityCfg("robot", body_names=ee_body_name)

            is_success = reach_subtask_term_signal(env, body_cfg).squeeze(-1).bool()
            return success_counters, is_success
        else:
            return success_counters, torch.zeros(env.num_envs, dtype=torch.bool, device=env.device)

    is_success = success_term.func(env, **success_term.params)
    success_counters = torch.where(is_success, success_counters + 1, torch.zeros_like(success_counters))
    success_flags = success_counters >= args_cli.num_success_steps

    return success_counters, success_flags


def extract_trajectory_from_plan(planner, robot_joint_names: list) -> tuple | None:
    """Extract (positions, velocities) from cuRobo plan.

    Args:
        planner: CuroboPlanner instance
        robot_joint_names: List of robot joint names

    Returns:
        (positions, velocities) tensors or None if no plan
    """
    if planner._current_plan is None:
        return None

    plan = planner._current_plan
    plan_joint_names = plan.joint_names
    T = len(plan.position)

    # Get positions and velocities
    positions = plan.position  # (T, num_plan_joints)
    velocities = plan.velocity  # (T, num_plan_joints)

    return positions, velocities, plan_joint_names


def run_simulation_loop(env, planners, success_term) -> list:
    """Run main simulation loop for data collection.

    Returns:
        List of collected demonstrations
    """
    collected_demos = []
    success_counters = torch.zeros(env.num_envs, dtype=torch.int32, device=env.device)

    # Initialize demo collector
    collector = SecondOrderDemoCollector(env.num_envs, env.device, dt=args_cli.dt)

    # Tracking
    env_planning = torch.ones(env.num_envs, dtype=torch.bool, device=env.device)
    env_plan_idx = torch.zeros(env.num_envs, dtype=torch.int32, device=env.device)
    env_step_counter = torch.zeros(env.num_envs, dtype=torch.int32, device=env.device)

    STEPS_PER_WAYPOINT = 1

    # Reset environment
    env.sim.reset()
    env.reset()

    print(f"Starting generation of {args_cli.num_demos} demonstrations...")

    is_datagen_task = "datagen" in args_cli.task.lower()
    action_dim = env.action_manager.total_action_dim
    robot_joint_names = env.scene["robot"].data.joint_names

    # Get EE body index for FK
    ee_body_name = env.command_manager.get_term("ee_pose").cfg.body_name
    ee_body_ids = env.scene["robot"].find_bodies(ee_body_name)[0]
    ee_body_idx = ee_body_ids[0] if isinstance(ee_body_ids, list) else int(ee_body_ids)

    with contextlib.suppress(KeyboardInterrupt) and torch.inference_mode():
        while simulation_app.is_running():
            # Plan motions for environments that need planning
            for env_id in range(env.num_envs):
                if env_planning[env_id]:
                    planner = planners[env_id]
                    planner.update_world()

                    # Get target pose
                    command = env.command_manager.get_command("ee_pose")
                    target_pos_b = command[env_id, :3]
                    target_quat_b = command[env_id, 3:7]

                    import isaaclab.utils.math as PoseUtils
                    asset = env.scene["robot"]
                    target_pos_w, target_quat_w = PoseUtils.combine_frame_transforms(
                        asset.data.root_pos_w[env_id:env_id+1],
                        asset.data.root_quat_w[env_id:env_id+1],
                        target_pos_b.unsqueeze(0),
                        target_quat_b.unsqueeze(0)
                    )

                    target_rot = PoseUtils.matrix_from_quat(target_quat_w)
                    target_pose = PoseUtils.make_pose(target_pos_w, target_rot)[0]

                    success = planner.plan_motion(target_pose, step_size=args_cli.dt, enable_retiming=True)

                    if success:
                        env_planning[env_id] = False
                        env_plan_idx[env_id] = 0
                        env_step_counter[env_id] = 0
                        print(f"[Env {env_id}] Planning succeeded")
                    else:
                        print(f"[Env {env_id}] Planning failed, retrying...")

            # Execute waypoints and collect data
            actions = torch.zeros((env.num_envs, action_dim), device=env.device)

            for env_id in range(env.num_envs):
                planner = planners[env_id]

                if (not env_planning[env_id] and
                    planner._current_plan is not None and
                    env_plan_idx[env_id] < len(planner._current_plan.position)):

                    # Get current waypoint
                    idx = env_plan_idx[env_id].item()
                    next_joint_state = planner._current_plan[idx]

                    # Get target positions and velocities
                    target_pos = next_joint_state.position
                    target_vel = next_joint_state.velocity
                    if target_pos.dim() > 1:
                        target_pos = target_pos.squeeze(0)
                        target_vel = target_vel.squeeze(0)

                    # Current robot state
                    current_pos = env.scene["robot"].data.joint_pos[env_id, :]
                    current_vel = env.scene["robot"].data.joint_vel[env_id, :]

                    # Map cuRobo joints to Isaac Lab
                    plan_joint_names = next_joint_state.joint_names
                    full_target_pos = current_pos.clone()
                    full_target_vel = current_vel.clone()

                    for i, joint_name in enumerate(plan_joint_names):
                        if joint_name in robot_joint_names:
                            isaac_idx = robot_joint_names.index(joint_name)
                            full_target_pos[isaac_idx] = target_pos[i]
                            full_target_vel[isaac_idx] = target_vel[i]

                    # Collect data: use current robot state
                    asset = env.scene["robot"]
                    eef_pos = asset.data.body_pos_w[env_id, ee_body_idx, :]
                    eef_quat = asset.data.body_quat_w[env_id, ee_body_idx, :]
                    obstacle_pos = get_obstacle_positions(env, env_id)

                    # Use Franka arm joints only (first 7)
                    collector.add_step(
                        env_id=env_id,
                        joint_pos=full_target_pos[:7],  # Arm joints
                        joint_vel=full_target_vel[:7],  # Arm velocities
                        eef_pos=eef_pos,
                        eef_quat=eef_quat,
                        obstacle_pos=obstacle_pos,
                    )

                    # Compute action
                    if is_datagen_task:
                        actions[env_id] = full_target_pos[:action_dim]
                    else:
                        delta = full_target_pos - current_pos
                        actions[env_id] = delta[:action_dim] * 2.0

                    # Step control
                    env_step_counter[env_id] += 1
                    if env_step_counter[env_id] >= STEPS_PER_WAYPOINT:
                        env_plan_idx[env_id] += 1
                        env_step_counter[env_id] = 0

                elif not env_planning[env_id]:
                    env_planning[env_id] = True

            # Step environment
            env.step(actions)

            # Check success
            success_counters, success_flags = check_success(env, success_term, success_counters)

            # Handle successful demos
            for env_id in range(env.num_envs):
                if success_flags[env_id]:
                    # Finalize and save episode
                    demo = collector.finalize_episode(env_id)
                    if demo is not None:
                        collected_demos.append(demo)
                        print(f"[Env {env_id}] Demo {len(collected_demos)} recorded (T={len(demo['actions'])})")

                    # Reset environment
                    env_id_tensor = torch.tensor([env_id], dtype=torch.int64, device=env.device)
                    env.reset(env_ids=env_id_tensor)
                    success_counters[env_id] = 0
                    env_planning[env_id] = True
                    planners[env_id].reset_plan()

            # Check if target reached
            if len(collected_demos) >= args_cli.num_demos:
                print(f"Target reached! {len(collected_demos)} demos collected.")
                break

            if env.sim.is_stopped():
                break

    return collected_demos


def main():
    """Main function for 2nd-order data generation."""
    # Create environment
    env, env_cfg, success_term = create_environment()

    # Initialize cuRobo planners
    planners = initialize_curobo_planners(env)

    # Run simulation loop
    demos = run_simulation_loop(env, planners, success_term)

    # Save demos to HDF5
    if len(demos) > 0:
        save_demos_to_hdf5(demos, args_cli.dataset_file)
    else:
        print("No demonstrations collected!")

    # Cleanup
    for env_id, planner in planners.items():
        if getattr(planner, "plan_visualizer", None) is not None:
            planner.plan_visualizer.close()

    env.close()
    print(f"Generation completed with {len(demos)} demonstrations")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nProgram interrupted by user.")
    simulation_app.close()
